import pandas as pd
import asyncio
from langsmith import Client, aevaluate
from dotenv import load_dotenv

# ç’°å¢ƒè¨­å®š
load_dotenv(r"C:\dev\ishikawa-Chatbot\ishikawa-Chatbot.env")

# è¨­å®š
NEW_DATASET_NAME = "SGU_Evaluation_Clean_v1" # æ–°ã—ã„ã‚¯ãƒªãƒ¼ãƒ³ãªåå‰
INPUT_FILE = "è³ªå•ã¨ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ã®å›ç­”é›†.xlsx"

async def create_clean_dataset_and_upload():
    client = Client()
    print(f"ğŸ“‚ Excelèª­ã¿è¾¼ã¿ä¸­: {INPUT_FILE}")

    # 1. Excelãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    try:
        df = pd.read_excel(INPUT_FILE)
        df.columns = [c.strip() for c in df.columns] # åˆ—åã®ã‚´ãƒŸå–ã‚Š
    except Exception as e:
        print(f"âŒ Excelèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return

    # å¿…è¦ãªåˆ—ãŒã‚ã‚‹ã‹ç¢ºèª
    if "Question" not in df.columns or "Answer" not in df.columns:
        print("âŒ ã‚¨ãƒ©ãƒ¼: Excelã« 'Question' ã¾ãŸã¯ 'Answer' åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # 2. æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆï¼ˆæ—¢ã«åŒåãŒã‚ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    if client.has_dataset(dataset_name=NEW_DATASET_NAME):
        print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{NEW_DATASET_NAME}' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚æ—¢å­˜ã®ã‚‚ã®ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    else:
        print(f"ğŸ†• æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{NEW_DATASET_NAME}' ã‚’ä½œæˆä¸­...")
        dataset = client.create_dataset(dataset_name=NEW_DATASET_NAME)
        
        # è³ªå•ã¨æ­£è§£(Ground Truth)ã‚’ç™»éŒ²
        for q, a in zip(df['Question'], df['Answer']):
            client.create_example(
                inputs={"question": str(q).strip()},
                outputs={"answer": str(a).strip()}, # ã“ã‚ŒãŒã€Œç†æƒ³ã®æ­£è§£ã€ã«ãªã‚‹
                dataset_id=dataset.id
            )
        print("âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†ï¼ã‚´ãƒŸãƒ‡ãƒ¼ã‚¿ã¯ã‚‚ã†ã‚ã‚Šã¾ã›ã‚“ã€‚")

    # 3. è¾æ›¸åŒ–ï¼ˆãƒãƒƒãƒãƒ³ã‚°ç”¨ï¼‰
    qa_pairs = {}
    for q, a in zip(df['Question'], df['Answer']):
        clean_q = str(q).strip()
        qa_pairs[clean_q] = str(a).strip()

    # 4. ãƒ¢ãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ï¼ˆExcelã®å›ç­”ã‚’ã€Œã‚·ã‚¹ãƒ†ãƒ å›ç­”ã€ã¨ã—ã¦è¿”ã™ï¼‰
    async def mock_system(inputs: dict):
        q = inputs.get("question")
        # å®Œå…¨ã«ä¸€è‡´ã™ã‚‹ã¯ãšï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè‡ªä½“ã‚’Excelã‹ã‚‰ä½œã£ãŸã®ã§ï¼‰
        return {"answer": qa_pairs.get(q, "Error: ãƒ‡ãƒ¼ã‚¿ä¸ä¸€è‡´")}

    print(f"ğŸš€ 'Answer'åˆ—ã‚’ {NEW_DATASET_NAME} ã®å®Ÿé¨“çµæœã¨ã—ã¦ç™»éŒ²ä¸­...")

    # 5. è©•ä¾¡å®Ÿè¡Œï¼ˆæ¡ç‚¹AIãªã—ã§ã€ã¾ãšã¯ç™»éŒ²ã ã‘è¡Œã†ï¼‰
    # â€»è‡ªå‹•æ¡ç‚¹ã‚’å…¥ã‚ŒãŸã„å ´åˆã¯ evaluators=[...] ã‚’è¿½åŠ ã—ã¦ãã ã•ã„
    await aevaluate(
        mock_system,
        data=NEW_DATASET_NAME,
        experiment_prefix="Production_Result_Fixed",
        max_concurrency=1
    )

    print(f"\nâœ¨ å®Œäº†ã—ã¾ã—ãŸï¼")
    print(f"LangSmithã§ '{NEW_DATASET_NAME}' ã‚’é–‹ãã€'Production_Result_Fixed' ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    asyncio.run(create_clean_dataset_and_upload())