import pandas as pd
import asyncio
import os
from dotenv import load_dotenv

# 1. ç’°å¢ƒè¨­å®š
# æ—¢å­˜ã® .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™
load_dotenv(r"C:\dev\ishikawa-Chatbot\ishikawa-Chatbot.env")

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from core.database import SupabaseClientManager 
    from services.llm import LLMService
    from services.search import SearchService
    from services import prompts 
except ImportError as e:
    print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    print("ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ 'evaluate.py' ã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ç½®ã„ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    exit(1)

# è¨­å®š
INPUT_FILE = "è³ªå•ã¨ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ã®å›ç­”é›†.xlsx"
OUTPUT_FILE = "comparison_result.xlsx"

# ==========================================
# æ”¹å–„å‰(Before)ã®ãƒ­ã‚¸ãƒƒã‚¯: å˜ç´”ãªãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ + ä¸Šä½5ä»¶
# ==========================================
async def generate_before_answer(question: str):
    llm = LLMService()
    db = SupabaseClientManager(os.getenv("SUPABASE_URL"), os.getenv("SUPABASE_SERVICE_KEY"))
    
    try:
        # 1. æ¤œç´¢ç”¨åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ä½œæˆ
        emb = await llm.get_embedding(question)
        
        # 2. å˜ç´”æ¤œç´¢ (ã‚¯ã‚¨ãƒªæ‹¡å¼µãªã—ã€Rerankãªã—)
        raw_docs = db.client.rpc("match_documents_hybrid", {
            "p_collection_name": "student-knowledge-base",
            "p_query_text": question,
            "p_query_embedding": emb,
            "p_match_count": 5  # ä¸Šä½5ä»¶ã®ã¿
        }).execute().data or []

        # 3. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
        context_str = "\n\n".join([d.get('content','') for d in raw_docs])
        
        # 4. å›ç­”ç”Ÿæˆ
        if not context_str:
            return "æ¤œç´¢çµæœãªã—"

        prompt = f"è³ªå•: {question}\n\n<context>\n{context_str}\n</context>"
        
        # LLMã§å›ç­”ç”Ÿæˆ
        res_stream = await llm.generate_stream(prompt, prompts.SYSTEM_GENERATION)
        answer = ""
        async for chunk in res_stream:
            if chunk.text: answer += chunk.text
            
        return answer.strip()

    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: {e}"

# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==========================================
async def main():
    print(f"ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­: {INPUT_FILE}")
    try:
        df = pd.read_excel(INPUT_FILE)
        # åˆ—åã®ç©ºç™½å‰Šé™¤
        df.columns = [c.strip() for c in df.columns]
    except Exception as e:
        print(f"âŒ èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return

    results = []
    
    print("ğŸš€ æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™...")
    print(f"{'-'*60}")
    print(f"{'è³ªå•':<30} | {'é€²æ—'}")
    print(f"{'-'*60}")

    for index, row in df.iterrows():
        question = str(row['Question']).strip()
        after_answer = str(row['Answer']).strip() # Excelã«ã‚ã‚‹æ”¹å–„å¾Œã®å›ç­”

        print(f"[{index+1}/{len(df)}] {question[:20]}... ", end="", flush=True)

        # Before(æ”¹å–„å‰)ã®å›ç­”ã‚’ç”Ÿæˆ
        before_answer = await generate_before_answer(question)
        
        print("âœ… å®Œäº†")

        # çµæœã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
        results.append({
            "No": index + 1,
            "Question": question,
            "Before_Answer (å˜ç´”æ¤œç´¢)": before_answer,
            "After_Answer (æ”¹å–„ç‰ˆ/Excel)": after_answer
        })

    # çµæœã‚’Excelã«ä¿å­˜
    result_df = pd.DataFrame(results)
    result_df.to_excel(OUTPUT_FILE, index=False)
    
    print(f"{'-'*60}")
    print(f"âœ¨ å®Œäº†ã—ã¾ã—ãŸï¼çµæœãƒ•ã‚¡ã‚¤ãƒ«: {OUTPUT_FILE}")
    print("ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã„ã¦ã€Båˆ—(Before)ã¨Cåˆ—(After)ã‚’è¦‹æ¯”ã¹ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    asyncio.run(main())